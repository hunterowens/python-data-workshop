{
 "metadata": {
  "name": "",
  "signature": "sha256:a1131db9cf193631721d3c46e2a6772aa59095c444f769ab4540431611630649"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Remember, the September Dataframe is awesome. Let's make a plot, by time, over the average number of bikes\n",
      "## First, we need to load the data\n",
      "from pandas import DataFrame\n",
      "import pandas as pd\n",
      "\n",
      "#some matplotlib magic to make our plots suck less\n",
      "pd.options.display.mpl_style = 'default'\n",
      "%matplotlib inline\n",
      "\n",
      "# Load From a CSV\n",
      "september_dataframe = pd.read_csv('./data/september_data.csv',names=['station_id','bikes','spaces','total_docks','timestamp'],\n",
      "                                  parse_dates=[4]) ## read CSV assumes header"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import dateutil\n",
      "\n",
      "## Wait, timestamp is a string, let's convert to a datetime with a map\n",
      "print september_dataframe['timestamp']\n",
      "september_dataframe['timestamp'] = september_dataframe['timestamp'].apply(lambda t: pd.to_datetime(t))\n",
      "print september_dataframe.describe\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0    2013-09-04 00:01:04.749425\n",
        "1    2013-09-04 00:01:04.749425\n",
        "2    2013-09-04 00:01:04.749425\n",
        "3    2013-09-04 00:01:04.749425\n",
        "4    2013-09-04 00:01:04.749425\n",
        "5    2013-09-04 00:01:04.749425\n",
        "6    2013-09-04 00:01:04.749425\n",
        "7    2013-09-04 00:01:04.749425\n",
        "8    2013-09-04 00:01:04.749425\n",
        "9    2013-09-04 00:01:04.749425\n",
        "10   2013-09-04 00:01:04.749425\n",
        "11   2013-09-04 00:01:04.749425\n",
        "12   2013-09-04 00:02:03.297171\n",
        "13   2013-09-04 00:02:03.297171\n",
        "14   2013-09-04 00:02:03.297171\n",
        "...\n",
        "10091028   2013-09-04 00:01:04.749425\n",
        "10091029   2013-09-04 00:01:04.749425\n",
        "10091030   2013-09-04 00:01:04.749425\n",
        "10091031   2013-09-04 00:01:04.749425\n",
        "10091032   2013-09-04 00:01:04.749425\n",
        "10091033   2013-09-04 00:01:04.749425\n",
        "10091034   2013-09-04 00:01:04.749425\n",
        "10091035   2013-09-04 00:01:04.749425\n",
        "10091036   2013-09-04 00:01:04.749425\n",
        "10091037   2013-09-04 00:01:04.749425\n",
        "10091038   2013-09-04 00:01:04.749425\n",
        "10091039   2013-09-04 00:01:04.749425\n",
        "10091040   2013-09-04 00:01:04.749425\n",
        "10091041   2013-09-04 00:01:04.749425\n",
        "10091042   2013-09-04 00:01:04.749425\n",
        "Name: timestamp, Length: 10091043, dtype: datetime64[ns]\n",
        "<bound method DataFrame.describe of           station_id  bikes  spaces  total_docks                  timestamp\n",
        "0                241      6       9           15 2013-09-04 00:01:04.749425\n",
        "1                242      4      11           15 2013-09-04 00:01:04.749425\n",
        "2                243      7       7           14 2013-09-04 00:01:04.749425\n",
        "3                244     15       4           19 2013-09-04 00:01:04.749425\n",
        "4                245      3      12           15 2013-09-04 00:01:04.749425\n",
        "5                246      6       4           10 2013-09-04 00:01:04.749425\n",
        "6                247      7       8           15 2013-09-04 00:01:04.749425\n",
        "7                248      7       8           15 2013-09-04 00:01:04.749425\n",
        "8                249     12       3           15 2013-09-04 00:01:04.749425\n",
        "9                250     12       7           19 2013-09-04 00:01:04.749425\n",
        "10               251      5      10           15 2013-09-04 00:01:04.749425\n",
        "11               252      9       6           15 2013-09-04 00:01:04.749425\n",
        "12                 5      0      19           19 2013-09-04 00:02:03.297171\n",
        "13                13      5      14           19 2013-09-04 00:02:03.297171\n",
        "14                14     13       2           15 2013-09-04 00:02:03.297171\n",
        "15                15      7       8           15 2013-09-04 00:02:03.297171\n",
        "16                16      8       7           15 2013-09-04 00:02:03.297171\n",
        "17                17      3      12           15 2013-09-04 00:02:03.297171\n",
        "18                19      7       8           15 2013-09-04 00:02:03.297171\n",
        "19                20      6       9           15 2013-09-04 00:02:03.297171\n",
        "20                21      8       7           15 2013-09-04 00:02:03.297171\n",
        "21                22      7       8           15 2013-09-04 00:02:03.297171\n",
        "22                23      7       8           15 2013-09-04 00:02:03.297171\n",
        "23                24     12       3           15 2013-09-04 00:02:03.297171\n",
        "24                25     15       8           23 2013-09-04 00:02:03.297171\n",
        "25                26     10      13           23 2013-09-04 00:02:03.297171\n",
        "26                27      3      16           19 2013-09-04 00:02:03.297171\n",
        "27                28     10       5           15 2013-09-04 00:02:03.297171\n",
        "28                29      5      10           15 2013-09-04 00:02:03.297171\n",
        "29                30      9       6           15 2013-09-04 00:02:03.297171\n",
        "...              ...    ...     ...          ...                        ...\n",
        "10091013         209      5       6           11 2013-09-04 00:01:04.749425\n",
        "10091014         210     17       2           19 2013-09-04 00:01:04.749425\n",
        "10091015         211     19       0           19 2013-09-04 00:01:04.749425\n",
        "10091016         212     18       1           19 2013-09-04 00:01:04.749425\n",
        "10091017         213      8       3           11 2013-09-04 00:01:04.749425\n",
        "10091018         214      4      11           15 2013-09-04 00:01:04.749425\n",
        "10091019         215      9       6           15 2013-09-04 00:01:04.749425\n",
        "10091020         216      9       6           15 2013-09-04 00:01:04.749425\n",
        "10091021         217     12       2           14 2013-09-04 00:01:04.749425\n",
        "10091022         218      7       4           11 2013-09-04 00:01:04.749425\n",
        "10091023         219      3       8           11 2013-09-04 00:01:04.749425\n",
        "10091024         220      1      18           19 2013-09-04 00:01:04.749425\n",
        "10091025         222     15       4           19 2013-09-04 00:01:04.749425\n",
        "10091026         223      6       9           15 2013-09-04 00:01:04.749425\n",
        "10091027         224      8       8           16 2013-09-04 00:01:04.749425\n",
        "10091028         225      9       6           15 2013-09-04 00:01:04.749425\n",
        "10091029         226      8       7           15 2013-09-04 00:01:04.749425\n",
        "10091030         227      4      11           15 2013-09-04 00:01:04.749425\n",
        "10091031         228      2       9           11 2013-09-04 00:01:04.749425\n",
        "10091032         229      8       3           11 2013-09-04 00:01:04.749425\n",
        "10091033         230     14       5           19 2013-09-04 00:01:04.749425\n",
        "10091034         231      7       8           15 2013-09-04 00:01:04.749425\n",
        "10091035         232      3      12           15 2013-09-04 00:01:04.749425\n",
        "10091036         233      9       6           15 2013-09-04 00:01:04.749425\n",
        "10091037         234     16       3           19 2013-09-04 00:01:04.749425\n",
        "10091038         236      5      10           15 2013-09-04 00:01:04.749425\n",
        "10091039         237     11       4           15 2013-09-04 00:01:04.749425\n",
        "10091040         238     13       2           15 2013-09-04 00:01:04.749425\n",
        "10091041         239     12       3           15 2013-09-04 00:01:04.749425\n",
        "10091042         240      9       2           11 2013-09-04 00:01:04.749425\n",
        "\n",
        "[10091043 rows x 5 columns]>"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set the Time Zone to Central \n",
      "#timezone = 'US/Central'\n",
      "#september_dataframe = september_dataframe['timestamp'].tz_localize('UTC').tz_convert(timezone)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Group by minute value (i.e. how many minutes have occured since midnight)\n",
      "#september_dataframe.\n",
      "station_monthly_groups = september_dataframe.groupby\\\n",
      "(september_dataframe['timestamp'].map(lambda t: 60*t.hour + t.minute))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Take the mean over each minute-since-midnight group\n",
      "station_monthly_averages = station_monthly_groups.mean()\n",
      "station_monthly_std = station_monthly_groups[\"bikes\"].std()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Takes the converted minute value and displays it as a readable time\n",
      "def minute_into_hour(x):\n",
      "    if x % 60 in range(0,10):\n",
      "        return str(x // 60) + \":0\" + str(x % 60)\n",
      "    else:\n",
      "        return str(x // 60) + \":\" + str(x % 60)\n",
      "times = station_monthly_averages.index.map(minute_into_hour)\n",
      "times_std = station_monthly_std.index.map(minute_into_hour)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add these new time values into our dataframe\n",
      "station_monthly_averages[\"timestamp\"] = times\n",
      "station_monthly_averages[\"bikes_available_std\"] = station_monthly_std\n",
      "\n",
      "station_monthly_averages.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Libaries\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.dates as dates\n",
      "\n",
      "#print station_monthly_averages.describe"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "grid_size = (1,1)\n",
      "count = 1\n",
      "nb_plots_per_page = 1\n",
      "ax = plt.subplot2grid(grid_size, (count % nb_plots_per_page,0))\n",
      "t = pd.to_datetime(station_monthly_averages['timestamp'])\n",
      "mu1 = station_montly_averages['bikes']\n",
      "#sigma1 = station_monthly_averages['bikes_available_std']\n",
      "ax.plot(t, mu1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}